<0.19.10.92.13.54.54.tmeadows@resumix.portal.com (Tim Meadows).0>
Type:     cmu.cs.scs
Who:      <speaker>Asst. Professor Harold L. Alexander</speaker>
Topic:    Research in Teleoperated and Cooperative Control 
          of Free-Flying Space Robots
Dates:    23-Oct-92
Time:     <stime>3:30</stime> - <etime>5:00 PM</etime>
Place:    <location>Baker Hall Adamson Wing</location>
Host:     Hagen Schempf, x6884
PostedBy: tmeadows on 19-Oct-92 at 13:54 from resumix.portal.com (Tim Meadows)
Abstract: 

  RI SEMINAR

 WHEN:	Friday, 23 October 1992; <stime>3:30</stime> - <etime>5:00 pm</etime>
	Refreshments to be served by 3:15 pm

 WHERE:	<location>Baker Hall Adamson Wing</location>

 SPEAKER:	<speaker>Asst. Professor Harold L. Alexander</speaker>

 TITLE:	Research in Teleoperated and Cooperative Control 
 	of Free-Flying Space Robots

<paragraph><sentence>The MIT Laboratory for Space Teleoperation and Robotics (LSTAR) is involved in the study of free-flying space robotic vehicles for performing extravehicular assembly, servicing, and repair</sentence>.  <sentence>LSTAR's experimental activities include both neutral-buoyancy and virtual-environment experiments that target the human-robot teleoperator interface, as well as cooperative, automatic control systems that work to aid the human operator</sentence>.</paragraph>

<paragraph><sentence>LSTAR's neutral-buoyancy robot, STAR, was designed to be serviceable, reliable, and flexible</sentence>.  <sentence>In order to support experiments combining human and automatic control, STAR is equipped with a real-time vision-based control system that has been used to demonstrate high-quality real-time control of STAR's position and orientation at a simulated worksite</sentence>.  <sentence>STAR has also been equipped recently with a three-degree-of-freedom manipulator arm to support 
experiments in teleoperator positioning dexterity as well as simple, autonomous fetch-and-return experiments</sentence>.</paragraph>

<paragraph><sentence>LSTAR's virtual-environment system is designed to focus on the remote-vision systems used by a remote-vehicle operator to sense and control the vehicle's position and orientation in its environment</sentence>.  <sentence>It is able to simulate teleoperation of vehicles functioning in two or three dimensions, with a variety of vehicle dynamics and visual environments</sentence>.  <sentence>It supports both fixed-monitor and helmet-mounted displays, with or without simulated head-tracking of the remote cameras</sentence>.  <sentence>Its primary current function is to 
study the use of sophisticated head-tracking stereoscopic camera 
systems and helmet-mounted displays, and to find ways to improve operator perception and control of vehicle motion using such systems</sentence>.</paragraph>

 HOST:	Hagen Schempf, x6884

---
****************|**************************|**************************
*               |                          |                         *
*Tim Meadows    |  Field Robotics Center   | Carnegie Mellon Univ.   *
*               |                          |                         *
*412-268-7085   |  Fax: 412-682-1793       | tmeadows@frc.ri.cmu.edu *
*               |                          |                         *
**********************************************************************

---
****************|**************************|**************************
*               |                          |                         *
*Tim Meadows    |  Field Robotics Center   | Carnegie Mellon Univ.   *
*               |                          |                         *
*412-268-7085   |  Fax: 412-682-1793       | tmeadows@frc.ri.cmu.edu *
*               |                          |                         *
**********************************************************************

